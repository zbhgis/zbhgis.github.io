# ENVI使用深度学习存在问题及解决

## 前言

前段时间试着用了ENVI的Deep Learning 1.2模块，感觉作为一个本地化的深度学习手段，其使用起来总体体验较为OK，就是比较依赖电脑配置

配置： Dell G15 i5 3050显卡 显存4GB CUDA计算能力达到要求

模块：实验使用的是像素分类模型，进行单个类别的分类

## 1.刚开始的配置检查报错

暂时不确定是否需要额外安装TensorFlow环境（不过我是已经装过了）

如果装完之后还是检测还是显示有问题（比如framework not found)，就不用管，直接跑模型，没有影响



## 2.TensorBoard可视化面板空白

在进行深度学习之后，会跳转到这个地址http://localhost:6006/#scalars，但是白屏了，不影响深度学习的使用，但是对应性能指标无法可视化，暂时未解决



## 3.输出的h5文件中，找不到精度

直接打开h5文件，在envi目录下的mertrics文件夹中，其中best和Last对应的模型的各个性能指标是一样的，但是他们会分别对应loss最低的和最后输出的，我是看recall来判断模型的识别能力



## 4.在绘制样本roi时，有的看不见

在envi563中，目前绘制样本如果超出了影像范围的时候，不会显示出来，推荐删除掉超出范围的那几个roi



## 5.Last model不设置输出路径

如果不设置的话他会在电脑的temp文件夹产生缓存，暂时不确定在软件关闭后自动删除，推荐设置好路径，输出之后可以快速找到并自己删除



## 6.训练模型的性能指标很好，但是把栅格图像拿去分类的效果很差；或者指标一般，分类效果好

测试过跟输入分类栅格文件格式没有关系，.tif和.dat的分类效果是一样的

大概率是样本划分的问题，导致结果不行；或者是分类影像问题，最好影像没有黑边；也有可能是最开始的模型能力就不行，可以在准备训练模型时，就多添加几个特征波段后再合成，再拿去训练



## 7.部分报错解决

1）一般的报错

首先检查必要的参数有没有设置错，比如输入的影像错误，输入的初始模型错误，参数没有填

其次检查是否存在同名文件，因为不能直接覆盖

再检查文件名和格式是否有问题，比如输出文件的格式为.dat还是默认还是.h5

最后检查电脑配置，可能最起码得有个性能在3050左右的显卡才带得动



2）runtime error：a patches perbatchsize is of 5 to large...

电脑配置不够，看看有没有升级到最新显卡，以及检查输入的训练和验证栅格是不是范围太大（刚开始可以试着输入小一点的栅格比如1500*1500）左右

产生这个报错，推荐不要去调整perbatchsize，因为调整之后虽然可能可以跑了没了这个报错，但是他的输出结果的各个性能指标会有问题，比如accuracy会一样，recall都是0



3）TensorFlow graphic framework is not found...

patch size 设置得太大了，调小一点



## 8.一些官方已经弄好的模快速调用

比如随机参数训练模型，推荐在左上角生成插件，其中在脚本中的” DISPLAY_NAME=‘xxxxxxxxx’ ”意思是拓展插件的名字，可以自己改，设置好之后点击菜单中的【Create Extension】即可生成

![image-20230719140931883](https://gitee.com/zbhgis/pic/raw/master/blog/image-20230719140931883.png)

![image-20230719141031685](https://gitee.com/zbhgis/pic/raw/master/blog/image-20230719141031685.png)

之后在ENVI的工具文件夹【Extension】中可以找到，双击可以直接调用

<!-- ##{"timestamp":1696888800}## -->